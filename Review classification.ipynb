{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6582ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import json\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4845c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to make it easier to handle the data \n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return \"NEGATIVE\"\n",
    "        elif self.score >= 4:\n",
    "            return \"POSITIVE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9776e",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd51b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 100000\n",
      "Sample review text: I ordered this for my wii and it is a great cable. Lets you play your came in HD so the picture is crystal clear. You can really tell the difference in HD and regular wii cord.\n",
      "Sample review score: 5.0\n"
     ]
    }
   ],
   "source": [
    "file = \"C:\\\\Users\\\\sadak\\\\Desktop\\\\datasets\\\\reviews.json\"\n",
    "reviews=[]\n",
    "with open(file) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review[\"reviewText\"], review[\"overall\"]))\n",
    "        \n",
    "print(\"Number of reviews:\",len(reviews))\n",
    "print(\"Sample review text:\",reviews[0].text)\n",
    "print(\"Sample review score:\",reviews[0].score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccfff720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 75505\n",
      "Negative reviews: 12346\n",
      "\n",
      "AFTER REDUCING POSITIVES\n",
      "Positive reviews: 13000\n",
      "Negative reviews: 12346\n"
     ]
    }
   ],
   "source": [
    "print(\"Positive reviews:\",len([i for i in reviews if (i.sentiment == \"POSITIVE\")]))\n",
    "print(\"Negative reviews:\",len([i for i in reviews if (i.sentiment == \"NEGATIVE\")]))\n",
    "\n",
    "# There are a lot more POSITIVE labels than negative ones\n",
    "# This might hamper with our model since POSITIVE is overly represented\n",
    "# Let us shrink our positive dataset to atleast close to 13000\n",
    "\n",
    "review_pos = [i for i in reviews if i.sentiment == \"POSITIVE\"]\n",
    "review_neg = [i for i in reviews if i.sentiment == \"NEGATIVE\"]\n",
    "review_pos = review_pos[:13000]\n",
    "\n",
    "reviews = review_neg + review_pos\n",
    "random.shuffle(reviews)\n",
    "\n",
    "print()\n",
    "print(\"AFTER REDUCING POSITIVES\")\n",
    "print(\"Positive reviews:\",len([i for i in reviews if (i.sentiment == \"POSITIVE\")]))\n",
    "print(\"Negative reviews:\",len([i for i in reviews if (i.sentiment == \"NEGATIVE\")]))\n",
    "\n",
    "# Much better now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea46bb9b",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76bdd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce63a942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [x.text for x in train]\n",
    "y_train = [y.sentiment for y in train]\n",
    "\n",
    "X_test = [x.text for x in test]\n",
    "y_test = [y.sentiment for y in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212b865",
   "metadata": {},
   "source": [
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12367b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML models work best with numerical data\n",
    "# We will convert it into a bag of words vector to pass to the model\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# This will come in handy later when testing\n",
    "X_test_vectors = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf9ab7b",
   "metadata": {},
   "source": [
    "## Fitting models to our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a408485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters for the models were chosen after running GridSearchCV\n",
    "\n",
    "lr = LogisticRegression(C=1, solver='saga')\n",
    "svc = LinearSVC(C=0.1)\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Voting classifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', lr), ('xgb', xgb), \n",
    "                                          ('svc', svc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c11940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sadak\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:02:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1, solver='saga')),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None)),\n",
       "                             ('svc', LinearSVC(C=0.1))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10530db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.878698224852071\n",
      "F1 score: [0.88157135 0.87568223]\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_clf.predict(X_test_vectors)\n",
    "print(\"Accuracy score:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred, average=None, labels=[\"POSITIVE\", \"NEGATIVE\"]))\n",
    "\n",
    "# Pretty good accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abfbab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can play with the model and see how it classifies our examples\n",
    "\n",
    "test = [\"this is the best product ever\", \"it did not work as expected, waste of money\",\"low quality product\"]\n",
    "voting_clf.predict(vectorizer.transform(test))\n",
    "\n",
    "# Not too shabby, seems to work quite well!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
